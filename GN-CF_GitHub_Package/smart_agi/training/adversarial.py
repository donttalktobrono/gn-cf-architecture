"""
Adversarial Curriculum System (Experiencer vs Saboteur)

This module implements a dual-role self-play training paradigm where:
- The EXPERIENCER (Solver) tries to solve tasks and maximize reward
- The SABOTEUR (Adversary) tries to create challenging scenarios

CRITICAL INSIGHT: Both roles share the SAME neural network/brain.
This forces the model to:
1. Understand problems from both perspectives
2. Develop genuine understanding rather than surface patterns
3. Create natural curriculum - as solver improves, saboteur must too
4. Prevent mode collapse and exploitation of simple tricks

The system alternates between roles, with the network learning to:
- Generate increasingly difficult challenges (as saboteur)
- Solve increasingly difficult challenges (as experiencer)
"""

import numpy as np
from typing import Optional, Tuple, List, Dict, Any, Callable
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
from collections import deque


class Role(Enum):
    """Role in the adversarial game."""
    EXPERIENCER = 1    # Solver - tries to succeed
    SABOTEUR = -1      # Adversary - tries to create challenges
    EVALUATOR = 0      # Neutral - assesses difficulty


@dataclass
class Challenge:
    """A challenge generated by the saboteur."""
    challenge_id: int
    parameters: Dict[str, Any]
    difficulty_estimate: float
    created_at: int  # Tick when created
    solved: bool = False
    solve_attempts: int = 0
    solve_time: Optional[int] = None
    
    def to_vector(self, dim: int = 32) -> np.ndarray:
        """Convert challenge to vector representation."""
        # Hash parameters to create deterministic vector
        param_str = str(sorted(self.parameters.items()))
        hash_val = hash(param_str)
        
        # Use hash as seed for reproducible random vector
        rng = np.random.RandomState(abs(hash_val) % (2**31))
        vec = rng.randn(dim).astype(np.float32)
        
        # Scale by difficulty
        vec *= self.difficulty_estimate
        
        return vec / (np.linalg.norm(vec) + 1e-8)


@dataclass
class SolveAttempt:
    """Record of an attempt to solve a challenge."""
    challenge_id: int
    success: bool
    reward: float
    steps_taken: int
    strategy_used: str
    tick: int


@dataclass
class AdversarialConfig:
    """Configuration for adversarial training."""
    # Role switching
    experiencer_steps: int = 10      # Steps as experiencer before switching
    saboteur_steps: int = 5          # Steps as saboteur before switching
    
    # Difficulty calibration
    target_success_rate: float = 0.5  # Target success rate (0.5 = balanced)
    difficulty_adjustment_rate: float = 0.1
    min_difficulty: float = 0.1
    max_difficulty: float = 2.0
    
    # Challenge pool
    max_challenges: int = 100
    challenge_lifetime: int = 500    # Ticks before challenge expires
    
    # Reward shaping
    solve_reward: float = 1.0
    fail_penalty: float = -0.1
    saboteur_reward_for_hard: float = 0.5
    saboteur_penalty_for_easy: float = -0.3
    
    # Learning
    learning_rate: float = 0.01
    discount_factor: float = 0.99


class ChallengeGenerator(ABC):
    """Abstract base class for challenge generators."""
    
    @abstractmethod
    def generate(self, difficulty: float, context: Dict[str, Any]) -> Challenge:
        """Generate a new challenge."""
        pass
    
    @abstractmethod
    def mutate(self, challenge: Challenge, mutation_strength: float) -> Challenge:
        """Mutate an existing challenge."""
        pass


class ParametricChallengeGenerator(ChallengeGenerator):
    """
    Generates challenges by sampling from parameter distributions.
    
    The saboteur learns to adjust these distributions to create
    appropriately difficult challenges.
    """
    
    def __init__(self, param_specs: Dict[str, Tuple[float, float, str]]):
        """
        Initialize generator.
        
        Args:
            param_specs: Dict mapping param_name to (min, max, distribution_type)
        """
        self.param_specs = param_specs
        self.next_id = 0
        
        # Learnable distribution parameters
        self.means = {
            name: (spec[0] + spec[1]) / 2
            for name, spec in param_specs.items()
        }
        self.stds = {
            name: (spec[1] - spec[0]) / 4
            for name, spec in param_specs.items()
        }
        
    def generate(self, difficulty: float, context: Dict[str, Any]) -> Challenge:
        """Generate a challenge with given difficulty."""
        parameters = {}
        
        for name, (min_val, max_val, dist_type) in self.param_specs.items():
            if dist_type == 'uniform':
                value = np.random.uniform(min_val, max_val)
            elif dist_type == 'normal':
                value = np.clip(
                    np.random.normal(self.means[name], self.stds[name] * difficulty),
                    min_val, max_val
                )
            elif dist_type == 'exponential':
                value = min_val + np.random.exponential(
                    (max_val - min_val) * difficulty / 2
                )
                value = np.clip(value, min_val, max_val)
            else:
                value = np.random.uniform(min_val, max_val)
            
            parameters[name] = value
        
        challenge = Challenge(
            challenge_id=self.next_id,
            parameters=parameters,
            difficulty_estimate=difficulty,
            created_at=context.get('tick', 0)
        )
        
        self.next_id += 1
        return challenge
    
    def mutate(self, challenge: Challenge, mutation_strength: float) -> Challenge:
        """Mutate a challenge."""
        new_params = {}
        
        for name, value in challenge.parameters.items():
            if name in self.param_specs:
                min_val, max_val, _ = self.param_specs[name]
                noise = np.random.normal(0, mutation_strength * (max_val - min_val))
                new_params[name] = np.clip(value + noise, min_val, max_val)
            else:
                new_params[name] = value
        
        return Challenge(
            challenge_id=self.next_id,
            parameters=new_params,
            difficulty_estimate=challenge.difficulty_estimate * (1 + np.random.uniform(-0.1, 0.1)),
            created_at=challenge.created_at
        )
    
    def update_distributions(self, successful_challenges: List[Challenge],
                            failed_challenges: List[Challenge],
                            learning_rate: float = 0.1):
        """Update distribution parameters based on solve outcomes."""
        # Move means toward parameters of challenges at target difficulty
        for name in self.param_specs.keys():
            if successful_challenges:
                success_mean = np.mean([c.parameters[name] for c in successful_challenges])
                # Increase difficulty: move away from successful params
                self.means[name] += learning_rate * (self.means[name] - success_mean) * 0.5
            
            if failed_challenges:
                fail_mean = np.mean([c.parameters[name] for c in failed_challenges])
                # Decrease difficulty: move toward failed params
                self.means[name] -= learning_rate * (self.means[name] - fail_mean) * 0.5


class ChallengePool:
    """Pool of active challenges."""
    
    def __init__(self, max_size: int = 100, lifetime: int = 500):
        """
        Initialize challenge pool.
        
        Args:
            max_size: Maximum number of challenges
            lifetime: Ticks before challenge expires
        """
        self.max_size = max_size
        self.lifetime = lifetime
        self.challenges: Dict[int, Challenge] = {}
        self.current_tick = 0
        
    def add(self, challenge: Challenge):
        """Add a challenge to the pool."""
        # Remove expired challenges
        self._cleanup()
        
        # Remove oldest if at capacity
        if len(self.challenges) >= self.max_size:
            oldest_id = min(self.challenges.keys())
            del self.challenges[oldest_id]
        
        self.challenges[challenge.challenge_id] = challenge
    
    def get(self, challenge_id: int) -> Optional[Challenge]:
        """Get a challenge by ID."""
        return self.challenges.get(challenge_id)
    
    def get_unsolved(self) -> List[Challenge]:
        """Get all unsolved challenges."""
        return [c for c in self.challenges.values() if not c.solved]
    
    def get_by_difficulty(self, target_difficulty: float, 
                          tolerance: float = 0.2) -> List[Challenge]:
        """Get challenges near target difficulty."""
        return [
            c for c in self.challenges.values()
            if not c.solved and abs(c.difficulty_estimate - target_difficulty) < tolerance
        ]
    
    def mark_solved(self, challenge_id: int, solve_time: int):
        """Mark a challenge as solved."""
        if challenge_id in self.challenges:
            self.challenges[challenge_id].solved = True
            self.challenges[challenge_id].solve_time = solve_time
    
    def record_attempt(self, challenge_id: int):
        """Record a solve attempt."""
        if challenge_id in self.challenges:
            self.challenges[challenge_id].solve_attempts += 1
    
    def tick(self):
        """Advance one tick."""
        self.current_tick += 1
        self._cleanup()
    
    def _cleanup(self):
        """Remove expired challenges."""
        expired = [
            cid for cid, c in self.challenges.items()
            if self.current_tick - c.created_at > self.lifetime
        ]
        for cid in expired:
            del self.challenges[cid]
    
    def get_stats(self) -> Dict[str, Any]:
        """Get pool statistics."""
        challenges = list(self.challenges.values())
        if not challenges:
            return {'count': 0}
        
        solved = [c for c in challenges if c.solved]
        
        return {
            'count': len(challenges),
            'solved_count': len(solved),
            'solve_rate': len(solved) / len(challenges),
            'avg_difficulty': np.mean([c.difficulty_estimate for c in challenges]),
            'avg_attempts': np.mean([c.solve_attempts for c in challenges])
        }


class AdversarialCurriculum:
    """
    Main adversarial curriculum controller.
    
    Manages the interplay between experiencer and saboteur roles,
    calibrates difficulty, and tracks learning progress.
    """
    
    def __init__(self, config: AdversarialConfig,
                 challenge_generator: ChallengeGenerator):
        """
        Initialize adversarial curriculum.
        
        Args:
            config: Configuration
            challenge_generator: Generator for challenges
        """
        self.config = config
        self.generator = challenge_generator
        self.pool = ChallengePool(config.max_challenges, config.challenge_lifetime)
        
        # Current state
        self.current_role = Role.EXPERIENCER
        self.role_steps = 0
        self.current_tick = 0
        
        # Difficulty tracking
        self.current_difficulty = 0.5
        self.success_history = deque(maxlen=100)
        
        # Learning history
        self.solve_attempts: List[SolveAttempt] = []
        self.generated_challenges: List[Challenge] = []
        
        # Role-specific embeddings (for the shared network)
        self.role_embeddings = {
            Role.EXPERIENCER: np.array([1, 0, 0], dtype=np.float32),
            Role.SABOTEUR: np.array([0, 1, 0], dtype=np.float32),
            Role.EVALUATOR: np.array([0, 0, 1], dtype=np.float32)
        }
        
    def get_role_embedding(self) -> np.ndarray:
        """Get embedding for current role."""
        return self.role_embeddings[self.current_role]
    
    def step(self) -> Tuple[Role, Optional[Challenge]]:
        """
        Advance one step in the curriculum.
        
        Returns:
            Tuple of (current_role, challenge_to_work_on)
        """
        self.current_tick += 1
        self.role_steps += 1
        self.pool.tick()
        
        # Check if should switch roles
        if self.current_role == Role.EXPERIENCER:
            if self.role_steps >= self.config.experiencer_steps:
                self._switch_role(Role.SABOTEUR)
        elif self.current_role == Role.SABOTEUR:
            if self.role_steps >= self.config.saboteur_steps:
                self._switch_role(Role.EXPERIENCER)
        
        # Get challenge based on role
        if self.current_role == Role.EXPERIENCER:
            challenge = self._select_challenge_to_solve()
        else:
            challenge = None  # Saboteur generates new challenges
        
        return self.current_role, challenge
    
    def _switch_role(self, new_role: Role):
        """Switch to a new role."""
        self.current_role = new_role
        self.role_steps = 0
    
    def _select_challenge_to_solve(self) -> Optional[Challenge]:
        """Select a challenge for the experiencer to solve."""
        # Get challenges near current difficulty
        candidates = self.pool.get_by_difficulty(self.current_difficulty, tolerance=0.3)
        
        if not candidates:
            candidates = self.pool.get_unsolved()
        
        if not candidates:
            return None
        
        # Prefer challenges with fewer attempts
        candidates.sort(key=lambda c: c.solve_attempts)
        return candidates[0]
    
    def generate_challenge(self, context: Dict[str, Any]) -> Challenge:
        """Generate a new challenge (saboteur action)."""
        challenge = self.generator.generate(self.current_difficulty, context)
        self.pool.add(challenge)
        self.generated_challenges.append(challenge)
        return challenge
    
    def record_solve_attempt(self, challenge_id: int, success: bool,
                            reward: float, steps: int, strategy: str):
        """Record result of a solve attempt."""
        attempt = SolveAttempt(
            challenge_id=challenge_id,
            success=success,
            reward=reward,
            steps_taken=steps,
            strategy_used=strategy,
            tick=self.current_tick
        )
        self.solve_attempts.append(attempt)
        
        # Update pool
        self.pool.record_attempt(challenge_id)
        if success:
            self.pool.mark_solved(challenge_id, self.current_tick)
        
        # Update success history
        self.success_history.append(success)
        
        # Adjust difficulty
        self._adjust_difficulty()
    
    def _adjust_difficulty(self):
        """Adjust difficulty based on recent success rate."""
        if len(self.success_history) < 10:
            return
        
        success_rate = np.mean(self.success_history)
        target = self.config.target_success_rate
        
        # If success rate is too high, increase difficulty
        # If success rate is too low, decrease difficulty
        adjustment = self.config.difficulty_adjustment_rate * (success_rate - target)
        
        self.current_difficulty = np.clip(
            self.current_difficulty + adjustment,
            self.config.min_difficulty,
            self.config.max_difficulty
        )
    
    def compute_reward(self, role: Role, success: bool,
                       challenge: Optional[Challenge] = None) -> float:
        """
        Compute reward for an action.
        
        Args:
            role: Role that took the action
            success: Whether the action was successful
            challenge: The challenge involved (if any)
        
        Returns:
            Reward value
        """
        if role == Role.EXPERIENCER:
            if success:
                return self.config.solve_reward
            else:
                return self.config.fail_penalty
        
        elif role == Role.SABOTEUR:
            if challenge is None:
                return 0.0
            
            # Saboteur is rewarded for creating challenges at target difficulty
            # that are eventually solved (not too hard) but take effort (not too easy)
            if challenge.solved:
                if challenge.solve_attempts > 1:
                    # Good: took multiple attempts
                    return self.config.saboteur_reward_for_hard
                else:
                    # Too easy: solved on first try
                    return self.config.saboteur_penalty_for_easy
            else:
                # Not yet solved - neutral
                return 0.0
        
        return 0.0
    
    def get_curriculum_state(self) -> Dict[str, Any]:
        """Get current curriculum state for the network."""
        return {
            'role': self.current_role.value,
            'role_embedding': self.get_role_embedding(),
            'difficulty': self.current_difficulty,
            'tick': self.current_tick,
            'success_rate': np.mean(self.success_history) if self.success_history else 0.5
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get curriculum statistics."""
        return {
            'current_role': self.current_role.name,
            'current_difficulty': self.current_difficulty,
            'current_tick': self.current_tick,
            'success_rate': np.mean(self.success_history) if self.success_history else 0.0,
            'total_attempts': len(self.solve_attempts),
            'total_challenges_generated': len(self.generated_challenges),
            'pool_stats': self.pool.get_stats()
        }
    
    def __repr__(self) -> str:
        stats = self.get_stats()
        return (f"AdversarialCurriculum(role={stats['current_role']}, "
                f"difficulty={stats['current_difficulty']:.2f}, "
                f"success_rate={stats['success_rate']:.2%})")


# ============ Flappy Bird Specific Challenge Generator ============

class FlappyBirdChallengeGenerator(ChallengeGenerator):
    """Challenge generator for Flappy Bird environment."""
    
    def __init__(self):
        self.next_id = 0
        
        # Parameter ranges for Flappy Bird
        self.param_ranges = {
            'gap_size': (80, 200),      # Vertical gap between pipes
            'pipe_speed': (2, 8),        # Horizontal speed of pipes
            'gravity': (0.3, 1.0),       # Gravity strength
            'jump_strength': (5, 12),    # Jump velocity
            'pipe_spacing': (150, 400),  # Horizontal distance between pipes
            'pipe_height_variance': (50, 200),  # Variance in pipe heights
        }
        
    def generate(self, difficulty: float, context: Dict[str, Any]) -> Challenge:
        """Generate a Flappy Bird challenge."""
        # Scale parameters by difficulty
        parameters = {}
        
        # Harder = smaller gaps
        gap_range = self.param_ranges['gap_size']
        parameters['gap_size'] = gap_range[1] - difficulty * (gap_range[1] - gap_range[0]) * 0.7
        
        # Harder = faster pipes
        speed_range = self.param_ranges['pipe_speed']
        parameters['pipe_speed'] = speed_range[0] + difficulty * (speed_range[1] - speed_range[0])
        
        # Harder = stronger gravity
        grav_range = self.param_ranges['gravity']
        parameters['gravity'] = grav_range[0] + difficulty * (grav_range[1] - grav_range[0]) * 0.5
        
        # Jump strength inversely scaled
        jump_range = self.param_ranges['jump_strength']
        parameters['jump_strength'] = jump_range[1] - difficulty * (jump_range[1] - jump_range[0]) * 0.3
        
        # Harder = closer pipes
        spacing_range = self.param_ranges['pipe_spacing']
        parameters['pipe_spacing'] = spacing_range[1] - difficulty * (spacing_range[1] - spacing_range[0]) * 0.5
        
        # Harder = more variance
        var_range = self.param_ranges['pipe_height_variance']
        parameters['pipe_height_variance'] = var_range[0] + difficulty * (var_range[1] - var_range[0])
        
        challenge = Challenge(
            challenge_id=self.next_id,
            parameters=parameters,
            difficulty_estimate=difficulty,
            created_at=context.get('tick', 0)
        )
        
        self.next_id += 1
        return challenge
    
    def mutate(self, challenge: Challenge, mutation_strength: float) -> Challenge:
        """Mutate a Flappy Bird challenge."""
        new_params = {}
        
        for name, value in challenge.parameters.items():
            if name in self.param_ranges:
                min_val, max_val = self.param_ranges[name]
                noise = np.random.normal(0, mutation_strength * (max_val - min_val) * 0.1)
                new_params[name] = np.clip(value + noise, min_val, max_val)
            else:
                new_params[name] = value
        
        new_difficulty = challenge.difficulty_estimate * (1 + np.random.uniform(-0.1, 0.1))
        new_difficulty = np.clip(new_difficulty, 0.1, 2.0)
        
        return Challenge(
            challenge_id=self.next_id,
            parameters=new_params,
            difficulty_estimate=new_difficulty,
            created_at=challenge.created_at
        )


if __name__ == "__main__":
    print("=== Adversarial Curriculum Tests ===\n")
    
    # Create Flappy Bird challenge generator
    generator = FlappyBirdChallengeGenerator()
    
    # Create curriculum
    config = AdversarialConfig(
        experiencer_steps=10,
        saboteur_steps=5,
        target_success_rate=0.5
    )
    
    curriculum = AdversarialCurriculum(config, generator)
    print(f"Created: {curriculum}\n")
    
    # Simulate training loop
    print("Simulating 100 steps...")
    for i in range(100):
        role, challenge = curriculum.step()
        
        if role == Role.SABOTEUR:
            # Generate a challenge
            new_challenge = curriculum.generate_challenge({'tick': i})
            if i % 20 == 0:
                print(f"  Tick {i}: Saboteur generated challenge {new_challenge.challenge_id} "
                      f"(difficulty={new_challenge.difficulty_estimate:.2f})")
        
        elif role == Role.EXPERIENCER and challenge:
            # Try to solve the challenge
            # Simulate success based on difficulty
            success_prob = 1.0 / (1.0 + challenge.difficulty_estimate)
            success = np.random.random() < success_prob
            
            curriculum.record_solve_attempt(
                challenge.challenge_id,
                success=success,
                reward=1.0 if success else -0.1,
                steps=np.random.randint(10, 100),
                strategy='neural'
            )
            
            if i % 20 == 0:
                print(f"  Tick {i}: Experiencer {'solved' if success else 'failed'} "
                      f"challenge {challenge.challenge_id}")
    
    print(f"\nFinal state: {curriculum}")
    print(f"\nStats: {curriculum.get_stats()}")
    
    # Show some generated challenges
    print("\nSample challenges:")
    for challenge in curriculum.generated_challenges[:3]:
        print(f"  Challenge {challenge.challenge_id}:")
        print(f"    Difficulty: {challenge.difficulty_estimate:.2f}")
        print(f"    Parameters: {challenge.parameters}")
